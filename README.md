# Information Retrieval System

A local IR system for searching news articles using hybrid retrieval (BM25 + TF-IDF + reranking).

## Setup

### Requirements
- Python 3.7+
- pip

### Installation

1. Create a virtual environment (recommended):
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. NLTK data will be downloaded automatically on first run. You have to restart the kernel after the requirements are successfully downloaded

## Running the System

```bash
python3 main.py
```

Or if you activated the virtual environment:
```bash
python main.py
```

On first run, the system will:
- Load and process all articles from `Articles.csv`
- Build BM25 and TF-IDF indices
- Save processed data to `saved_data/` folder

Subsequent runs will load the preprocessed data directly.

## Usage

### Commands

- `search <query>` - Search for articles matching the query
- `stats` - Display index statistics
- `eval` - Run evaluation on test queries
- `quit` - Exit the system

### Example Queries

```
search oil prices decline
search Hong Kong stock market
search Saudi Arabia production
search Karachi transport
```

## System Architecture

### Preprocessing
- Lowercasing
- Special character removal
- Tokenization
- Stopword removal
- Porter stemming
- Bigram/trigram extraction

### Retrieval Pipeline
1. **BM25 Scoring** - Probabilistic relevance ranking
2. **TF-IDF Scoring** - Vector space model with cosine similarity
3. **Score Combination** - Weighted average (60% BM25, 40% TF-IDF)
4. **Reranking Heuristics**:
   - +10% boost for query terms in heading
   - +15% boost for exact phrase matches
   - -5% penalty for very short documents (<50 words)

### Evaluation
Test set contains 10 queries with manually labeled relevant documents.

Metrics:
- Precision@5
- Precision@10
- Recall@10
- Average query time

## Files

- `main.py` - Main IR system code
- `Articles.csv` - News articles dataset
- `test_queries.json` - Evaluation test set
- `requirements.txt` - Python dependencies
- `saved_data/` - Preprocessed data (generated on first run)
- `evaluation_results.txt` - Evaluation output (generated by eval command)

## Notes

- The system runs completely locally (no cloud services)
- Preprocessing is done once and cached
- Uses standard IR libraries (rank-bm25, sklearn)
